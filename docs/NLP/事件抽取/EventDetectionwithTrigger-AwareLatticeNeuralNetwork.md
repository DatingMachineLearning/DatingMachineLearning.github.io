# Event Detection with Trigger-Aware Lattice Neural Network

## Introduction

事件检测(ED)的目的是在原始文本中定位触发词，然后将它们分类为正确的事件类型。在这一任务中，基于神经网络的模型成为近年来的主流。然而，当涉及到没有自然分隔符的语言时，会出现两个问题，例如中文。首先，基于词的模型存在字触发词不匹配的问题，限制了方法的性能。此外，即使触发词能够被准确定位，触发词多义性的模糊性仍然会影响触发词的分类阶段。为了同时解决这两个问题，我们提出了触发感知格子神经网络（TLNN）。

1. 该框架动态地整合了单词和字符信息，从而避免了触发词不匹配的问题。
2. 此外，对于多义字和多义词，我们借助外部语言知识库对其所有意义进行建模，以缓解歧义触发的问题。

在两个基准数据集上的实验表明，我们的模型能够有效地解决这两个问题，并显著优于现有的方法，给出了最好的结果。本文的源代码可以从https://github.com/thunlp/TLNN获得。

## 论文试图解决什么问题？

1. 在触发词识别阶段，触发词不匹配问题会严重影响事件检测系统的性能。因为在没有自然分隔符的语言中，主流的方法大多是基于词的模型，在这种模型中，分词作为一个必要的预处理步骤应该首先进行。这些分词方法忽略了一个重要问题，即触发词可能是一个词的特定部分或包含多个词。
2. 在**触发词识别**中能够正确地检测到触发词的位置，**触发词分类**仍然会受到多义词固有的歧义问题的严重影响。因为具有多个词义的触发词可以分为不同的事件类型。

为了进一步说明上述两个问题确实存在，我们手工统计了两个广泛使用的数据集上不匹配触发词和多义触发词的比例。统计结果如表1所示，我们可以观察到触发词不匹配和触发多义的数据占了相当大的比例，进而影响了任务。

## 这是否是一个新的问题？

不是，是传统的事件抽取问题。

## 这篇文章要验证一个什么科学假设？

验证所提出的模型，利用分层表示和树状 LSTM 是否有利于事件抽取。

## 有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？

- 关系抽取

- 神经网络

研究员：Zeng, 

[Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification](https://www.semanticscholar.org/paper/6b8b2075319accc23fef43e4cf76bc3682189d82)

## 结论

我们提出了一种新的事件检测框架TLNN，它可以同时解决触发词不匹配和多触发点的问题。

通过分层表示学习和触发感知特征提取，TLNN能有效地利用多粒度信息，学习深度语义特征。在两个真实数据集上的实验表明，TLNN能够有效地解决这两个问题，并比各种神经网络模型得到更好的经验结果。在未来的工作中，我们将在更多的语言上进行实验

## 问题引入



## 方法

（1）分层表示学习，它以无监督的方式揭示了字符级、词级和语义级的嵌入向量。
（2）触发感知特征抽取器，通过树状结构的LSTM模型自动提取不同层次的语义特征。
（3）序列标记符，用于计算每个字符候选者被触发的概率。



![](C:/Users/Administrator/Desktop/git_repo/DatingMachineLearning.github.io/docs/NLP/img/466390f8f9336883f0c217ff03b90e41_1_Figure_2.png)





为了缓解触发词的错误匹配问题，创建一个path链接某个词开始和结束位置之间所有词的单元状态（cell state）。
该模型分为三个阶段的处理流程：
1） **预处理模块**：使用Skip-Gram模型将句子序列S={c1,c2,…,cN}转化为字级别和词级别的向量。同时，基于HowNet得到所有的与该句子序列中有关的字和词的注释信息向量（sense-level embedding）。
2） **特征提取模块**
使用触发词感知的网格LSTM（Trigger-aware lattice LSTM）作为特征提取器，它可以同时提取character-level、 word-level、sense-level（使用HowNet对多义词的注释）的信息。
3) **序列标注模块**
采用BIO标注方式，使用CRF预测序列的标注结果，并获得序列标注的loss。



![466390f8f9336883f0c217ff03b90e41_3_Figure_3](C:/Users/Administrator/Desktop/git_repo/DatingMachineLearning.github.io/docs/NLP/img/466390f8f9336883f0c217ff03b90e41_3_Figure_3.png)
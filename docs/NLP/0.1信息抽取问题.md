# 信息抽取问题

本文参考了以下文章：

> [一文看懂NLP中的文本情感分析任务-InfoQ](https://www.infoq.cn/article/xgossrfzrsupbltggjcm)
>
> [关系抽取综述 | 范永勇](http://www.fanyeong.com/2018/08/11/relation-extration-overview/) 
>
> [关系抽取(分类)总结 | 天空的城](http://shomy.top/2018/02/28/relation-extraction/) 
>
> [综述&实践 | NLP中的命名实体识别 (NER)  (一)  - 知乎](https://zhuanlan.zhihu.com/p/54852391)

## 目标

1. 理解 NER/Sentiment Recognition/Relation Extraction；
2. 两次总结分享 (最好包括论文分享) ；
3. 熟悉NLP常用Deep learning 方法。

## 概念

[Introduction-NLP/3.二元语法与中文分词.md at master · NLP-LOVE/Introduction-NLP](https://github.com/NLP-LOVE/Introduction-NLP/blob/master/chapter/3.%E4%BA%8C%E5%85%83%E8%AF%AD%E6%B3%95%E4%B8%8E%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D.md)

**模型**指的是对事物的数学抽象，那么**语言模型**指的就是对语言现象的数学抽象。准确的讲，给定一个句子 w，语言模型就是计算句子的出现概率 p(w) 的模型，而统计的对象就是人工标注而成的语料库。

关系提取 (Relation Extraction, RE) 是信息提取 ( Information Extraction， IE) 中的一个重要子任务。

> International Business Machines Corporation (IBM or the company) was incorporated in the State of New York on June 16, 1911.

我们可以从上面这段文本中抽取出如下三元组（triples）关系：

- Founding-year (IBM, 1911)
- Founding-location (IBM, New York)

信息提取还有其他子任务，关系如下：

- 信息提取
  - 命名实体识别 (named-entity-recognition) ：命名实体识别(NER)的任务是找到文本中提到的每个命名实体，并标记其类型。构成命名实体类型的是特定于任务的;人员、地点和组织是常见的。一旦提取了文本中的所有命名实体，就可以将它们链接到与实际实体相对应的集合中。
  - 关系抽取 (relation extraction) ：关系抽取，寻找和分类命名体之间的语义关系。比如“小明的爸爸是王刚”，就可以抽取出关系三元组 `[父子, 小明, 王刚]`。
  - 情感分析 (Sentiment Recognition) ：文本情感分析旨在分析出文本中针对某个对象的评价的正负面，比如“我觉得华为手机拍照非常好”就是一个正面评价。情感分析主要有五个要素，`（entity/实体，aspect/属性，opinion/观点，holder/观点持有者，time/时间）`，其中实体和属性合并称为评价对象(target)。情感分析的目标就是从非结构化的文本评论中抽取出这五个要素。在这个例子中也就是 `(华为手机, 拍照, 非常好, 我, time )`

## 关系提取 (Relation Extraction)

### 为什么要进行关系提取

- 创建新的结构化知识库(knowledge base)并且增强现有知识库

- 构建垂直领域知识图谱：医疗，化工，农业，教育等

- 支持上层应用：问答，搜索，推理等。比如，对于这样一个提问：

  > The granddaughter of which actor starred in the movie “E.T.”?

  可以用如下的关系推理表示：
  `(acted-in ?x "E.T.") && (is-a ?y actor) && (granddaughter-of ?x ?y)`

下面是 how 的部分
### 基于规则与词典的模式匹配方法

类似于正则表达式的方法去匹配实体和关系，相当于是记住了语法规则。比如：

对于`IS-A`这样的关系，我们可以使用如下的规则进行抽取：

> 在座的所有 X 都是 Y
>
> X 就是个 Y
>
> X 除了是 Y 还能是什么
>
> 包括 X 在内的所有 Z 都是 Y
>
> 所有 Y，包括 X 

还可以使用实体识别（Named Entity tags）：

> 创立（人，组织）
>
> 治愈（药物，病）

这样的关系想当然很好，但是人和组织之间可能存在其他关系，比如解散、加入、投资……要用更确切的规则进行限制的话，比如，要表示实体`PERSON`和`ORGANIZATION`之间的`POSITION`(职务)关系，我们可以定义一些规则：

> PERSON, POSITION of ORG
> • George Marshall, Secretary of State of the United States
>
> PERSON(named|appointed|chose|etc.) PERSON Prep? POSITION
> • Truman appointed Marshall Secretary of State
>
> PERSON [be]? (named|appointed|etc.) Prep? ORG POSITION
> • George Marshall was named US Secretary of State

### 监督学习方法

将关系抽取问题看作是多分类问题，每种关系作为一种类别。通过对标签数据的学习训练出一个分类器（classifier）即可。主要难点有两个：

- 特征构建：传统的基于机器学习的方法会使用一些NLP技术构建组合特征，一般基于词性标注、依存分析等 [依存句法分析 - 李理的博客](http://fancyerii.github.io/books/depparser/#%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BBdependency-relation)。

- 标签数据的获取：监督学习的效果直接取决于训练数据集的大小和质量，但是获得大量的标注数据的代价是非常昂贵的。那么如何解决这个问题呢？我们可以通过远程监督学习（distant supervision）的方法，从已有信息里得到大量的标签数据。

### 半监督和无监督方法

#### 基于种子的启发式算法 (Seed-­based or bootstrapping approach) 

> 参考论文 *[Hearst et al. 1992] Automatic acquisition of hyponyms from large text corpora.*

这个算法还是很有趣的，基本的思路是这样的：我们先准备一些准确率很高的种子实体-关系组，比如：`Jack Ma/Alibaba/Founder-of`这种。然后，

- 以这些种子实例为基础，去语料库里找出所有相关的句子
- 对这些句子的上下文进行分析，找出一些可靠的 pattern
- 然后再通过这些 pattern 去发现更多的实例
- 通过新的实例再去发掘出新的 pattern，如此往复，直到收敛
  整个过程像滚雪球一样，越滚越大…

这种方式类似于小学一道经典的数学题：统计池塘中鱼的数量。思路是从池塘中随机抓一定数量的鱼打标记然后放生，一段时间后再抓一批鱼，根据这批鱼中带记号的鱼的数量推断出池塘中鱼的总数。

通俗来讲就是从数据集中选取一批种子实例(seed instances)，学习完这些种子实例之后应用到大规模语料库中。这种学习方式形象地称之为自助学习。**缺点显而易见，精确度低且不能解决语义漂移（semantic drift）**

综上所述，每种学习方式都有很强的局限性。因此*Mintz*提出了一种新型的学习方式，称之为**远程监督**。

> [Distant supervision for relation extraction 远程监督 - 知乎](https://zhuanlan.zhihu.com/p/315450600)

#### 远程监督学习 (Distant Supervision) 

> 参考论文 [Mintz et al.2009] Distant supervision for relation extraction without labeled data

远程监督是一种增强的监督学习，其主要依赖于远程知识库（KB），例如现如今比较常用的 FreeBase、YaGo、DBPedia 等知识库作为基础，根据这些知识库中现有的实体和对应关系，对获取的语料进行快速标注，具体基于下列idea：

> If two entities participate in a relation, all sentences that mention these two entities express that relation.

若两个实体在一个关系中，则所有提到这两个实体的句子都表达了这个关系。

缺点：

- **假设可能不成立，也因此会出现很多错误标签。**这个很好理解，比如有以下两段话，我们本来打算抽取的关系是Founder-of，但是很明显，第二句表达的并不是这个意思，因此出现了标签错误。：

  > **Steve Jobs** was the co-founder and CEO of **Apple** and formerly Pixar.
  > **Steve Jobs** passed away the day before **Apple** unveiled iPhone4S in late 2011.

- **基于手动的特征工程效率不高**。Mintz 的文章，在获得标签数据后，会根据句子出现的频率构建一组特征，然后去训练一个分类器。这些特征大多是基于NLP技术的，比如词性标注，句法解析等。我们知道这些NLP技术还不是特别完美，会出现大量错误，而这些错误会在关系抽取系统累积传播，从而影响最终的分类效果。

为了改善远程监督的方法，有以下改进：

- 针对标签错误问题

  - 有一论文提出了一个增强版的远程监督假设： *If two entities participate in a relation, **at least one sentence** that mentions these two entities might express that relation.* ，提出使用无向图模型去预测实体之间的关系以及哪个句子表达了这个关系，与 [Mintz et al.2009]相比错误率减少了 31%。*[Riedel et al. 2010]Modeling Relations and Their Mentions without Labeled Text*
  - 引入attention机制，解决了[Riedel et al. 2010]和PCNN [Zeng et al.,2015]中信息利用不充分的问题 (只用一个instance来代表一个relation) 。引入selective attention机制，缓解了远程监督学习中标签错误的问题。 *[Lin et al., 2016] Neural Relation Extraction with Selective Attention over Instances*

- 针对特征工程的问题

  - 摒弃了手工特征工程，使用卷积神经网络来自动提取特征，提升了效果。*CNN [Zeng et al., 2014] Relation classification via convolutional deep neural network*

  - 使用multi-instance learning来缓解远程监督学习标签错误的问题，提出了分段CNN的概念 (Piecewise Convolutional Neural Networks) ，进一步提升了特征提取的效果。*PCNN [Zeng et al.,2015] Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks*

  - 提出了一种基于端到端神经网络的关系抽取模型。该模型使用双向 LSTM (Long-Short Term Memory，长短时记忆模型) 和树形 LSTM 同 时对实体和句子进行建模。 *[Miwa et al. 2016] End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures*

## 命名实体识别 (Name Entity Recognition)

### 为什么要进行命名实体识别

上文提到，NER是在一段文本中，将预先定义好的实体类型识别出来。例如，如果事先定义好的实体类型包含，“人名”，“地名”，“组织”等。

> 输入，“小丽去深圳参加了腾讯公司的面试”。
> 那么输出为，“小丽/人名 去 深圳/地名 参加了 腾讯公司/组织 的面试”。

NER任务是很多任务的基础，被广泛地应用到了以下的领域中：

- 信息抽取
- 关系抽取
- 语法分析
- 信息检索
- 问答系统
- 机器翻译等

### 常用方法

与关系提取类似，NER 也有：

- 基于规则与词典的模式匹配方法：类似于词表匹配，这种方法准确率高，召回率低，对于新词缺乏发现能力，并且往往需要领域专家帮忙维护知识库。
- 无监督学习方法：比较典型的是基于聚类的方法。 *D. Nadeau and S. Sekine, “A survey of named entity recognition and classification,” Lingvisticae Investigationes, vol. 30, no. 1, pp 3–26, 2007.）*
- 监督学习方法：分类模型，如SVM, 决策树, Adaboost 等，通常将每个字符的标签当成一个类别进行文本分类；而序列标注模型如CRF等，通常将NER问题理解为一个最大概率序列的问题，根据观测序列（通常指字符）预测隐藏序列（字符的标签）。常用的特征包括但不限于词是否再句子第一个位置出现；词缀，前缀和后缀等；目标词前后n个字符划定窗口，窗口内词的词性，orthographic等等。


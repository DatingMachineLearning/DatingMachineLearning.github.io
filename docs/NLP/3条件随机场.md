# 条件随机场

> 翻译自 [Introduction to Conditional Random Fields](https://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)

想象一下，你有一系列关于你一个月生活的自拍照，你想用它代表的活动标记每个图像（吃，睡觉，驾驶等）。 你打算怎么做？

一种方法是忽略自拍的顺序性，并构建每个图像分类器。 例如，考虑到一个月的标记快照，你可以了解凌晨6点拍摄的黑暗图像往往是睡觉，有很多鲜艳色彩的图像往往是关于跳舞，汽车的图像是关于驾驶的，等等。

但是，通过忽略这个顺序方面，你丢失了很多信息。 

例如，如果你看到嘴的特写图片会发生什么 - 是关于唱歌或吃什么？ 如果你知道以前的图像是你吃或烹饪的照片，那么这幅画更有可能关于进食的; 然而，如果之前的图像包含你唱歌跳舞，那么这可能代表了唱歌。

因此，为了提高我们标签程序的准确性，我们应该包含附近照片的标签，这正是条件随机场所做的。

## 分词标记 Part-of-Speech Tagging

让我们更详细地进入一些常见的词性标记 (POS) 的常见例子。

在 POS 标记中，目标是用标签标记一个句子（一系列 word 或 token），例如（ADJECTIVE, NOUN, PREPOSITION, VERB, ADVERB, ARTICLE）等标签。

例如，鉴于“Bob drank coffee at Starbucks”的句子，标签可能是“Bob（名词）drank （动词）coffee （名词）at （介词）Starbucks（名词）”。

因此，让我们建立一个 CRF ，以用他们的言论标记句子。 就像任何分类器一样，我们首先需要决定一个 **特征函数**。

### CRF 的特征函数

在 CRF 中, 每个特征函数 $f$ 有以下输入：

- 句子 $s$
- 单词在句子中的位置 $i$
- 当前单词的标签 $l_i$​
- 前一个单词的标签 $l_{i-1}$

并输出一个实数（尽管数字通常只是0或1）。

(注意：通过限制我们的特性只依赖于当前和以前的标签，而不是整个句子中的任意标签，我实际上是在构建一个 **线性链CRF** 的特殊情况。为了简单起见，我将在这篇文章中忽略一般的 CRF )

例如，当前一个单词是“Very”，一个特征函数可以测量我们有多怀疑当前单词应该被标记为形容词。

### 从特征到概率

然后，通过给每一个特征函数 $f_j$ 一个权重 $\lambda_j$ （将在下面谈谈如何从数据中学习这些权重），给出一个句子 $s$​，我们现在可以通过给一个句子中的所有单词上添加权重特征计算标签 $l$ 的得分：
$$
score(l | s) = \sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})
$$
第一个求和遍历每个特征函数 $j$，内部求和遍历句子的每个位置。

最后，我们可以将这些分数转化为概率 $p(l|s)$，通过指数和标准化在0和1之间：
$$
p(l | s) = \frac{exp[score(l|s)]}{\sum_{l’} exp[score(l’|s)]} = \frac{exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})]}{\sum_{l’} exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l’_i, l’_{i-1})]}
$$

## 特征函数的例子

那么这些特征函数是什么样的？ POS标记功能的例子可以包括：
$$
f_1(s, i, l_i, l_{i-1}) = 
\left\{
\begin{array}{**lr**}  
1, &\text{当 $l_i$ = ADVERB 且以 “-ly” 结尾}\\
0, &\text{否则}
\end{array}
\right.
$$

如果与此特征相关联的权重 $λ_1$ 大于零而且很大，则此特征基本上是指我们更喜欢将以 "-ly" 结尾的单词标记为 ADVERB。

$$
f_2(s, i, l_i, l_{i-1}) = 
\left\{
\begin{array}{**lr**}  
1, &\text{当 i = 1, $l_i$ = VERB 且这个句子 s 以问号结尾}\\
0, &\text{否则}
\end{array}
\right.
$$

同样，如果与此特征相关的权重 $λ_2$ 是大的且为正的，那么将 VERB 分配给问句中的第一个单词的标签 (例如，“Is this a sentence beginning with a verb?”) 是首选。

$$
f_3(s, i, l_i, l_{i-1}) = 
\left\{
\begin{array}{**lr**}  
1, &\text{当 i = 1, $l_{i-1}$ = ADJECTIVE 且  $l_{i}$ = NOUN }\\
0, &\text{否则}
\end{array}
\right.
$$

同样，这个特征的权重为正意味着形容词后面往往跟着名词。
$$
f_4(s, i, l_i, l_{i-1}) = 
\left\{
\begin{array}{**lr**}  
1, &\text{当 i = 1, $l_{i-1}$ = PREPOSITION 且  $l_{i}$ = PREPOSITION }\\
0, &\text{否则}
\end{array}
\right.
$$
负权重 $\lambda_4$ 意味着介词后面一般不是介词，所以当这种情况发生的时候，我们应该尽量避免打上标签。

那就是它！ 总结：要构建 CRF，你只需定义一系列特征函数（这可以取决于整个句子，当前位置，和附近的标签），将其分配权重，并将它们全部添加在一起，必要时在最后转换为概率。

现在让我们退后一步，并将 CRF 与其他一些常用的机器学习技术进行比较。





[Introduction-NLP/6.条件随机场与序列标注.md at master · NLP-LOVE/Introduction-NLP](https://github.com/NLP-LOVE/Introduction-NLP/blob/master/chapter/6.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E4%B8%8E%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8.md)

**线性链条件随机场**的定义如下:
$$
p(\boldsymbol{y} \mid \boldsymbol{x})=\frac{1}{Z(\boldsymbol{x})} \prod_{t=1}^{T} \exp \left\{\sum_{k=1}^{K} \boldsymbol{w}_{k} f_{k}\left(y_{t-1}, y_{t}, \boldsymbol{x}_{t}\right)\right\}
$$

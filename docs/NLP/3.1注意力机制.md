# 注意力机制

## Seq2Seq 模型

Seq2Seq（Sequence-to-Sequence）模型能够应用于机器翻译、语音识别等各种序列到序列的转换问题。一个 Seq2Seq 模型包含**编码器（Encoder）**和**解码器（Decoder）**两部分，它们通常是两个不同的 RNN。如下图所示，将编码器的输出作为解码器的输入，由解码器负责输出正确的翻译结果。

提出 Seq2Seq 模型的相关论文：

* [Sutskever et al., 2014. Sequence to sequence learning with neural networks](https://arxiv.org/pdf/1409.3215.pdf)
* [Cho et al., 2014. Learning phrase representaions using RNN encoder-decoder for statistical machine translation](https://arxiv.org/abs/1406.1078)

这种编码器-解码器的结构也可以用于图像描述（Image captioning）。将 AlexNet 作为编码器，最后一层的 Softmax 换成一个 RNN 作为解码器，网络的输出序列就是对图像的一个描述。

![seq2seq](img\seq2seq.png)

###  选择最可能的句子

机器翻译用到的模型与语言模型相似，只是用编码器的输出作为解码器第一个时间步的输入（而非 0）。因此机器翻译的过程其实相当于建立一个条件语言模型。

由于解码器进行随机采样过程，输出的翻译结果可能有好有坏。因此需要找到能使条件概率最大化的翻译，即

$$
{\arg\max}_{y^{⟨1⟩}, ..., y^{⟨T\_y⟩}}P(y^{⟨1⟩}, ..., y^{⟨T_y⟩} | x)
$$
解决此问题最常使用的算法是**集束搜索（Beam Search）**。

为什么不用贪心搜索(**Greedy Search**)呢？贪心搜索是一种来自计算机科学的算法，生成第一个词的分布以后，它将会根据你的条件语言模型挑选出最有可能的第一个词进入你的机器翻译模型中，在挑选出第一个词之后它将会继续挑选出最有可能的第二个词，然后继续挑选第三个最有可能的词，这种算法就叫做贪心搜索，但是你真正需要的是一次性挑选出整个单词序列，从$y^{<1>}$、$y^{<2>}$到$y^{<T_{y}>}$来使得整体的概率最大化。所以这种贪心算法先挑出最好的第一个词，在这之后再挑最好的第二词，然后再挑第三个，这种方法其实并不管用，为了证明这个观点，我们来考虑下面两种翻译。

![greedy_trans](img\greedy_trans.jpg)

第一串翻译明显比第二个好，所以我们希望机器翻译模型会说第一个句子的$P(y|x)$比第二个句子要高，第一个句子对于法语原文来说更好更简洁，虽然第二个也不错，但是有些啰嗦，里面有很多不重要的词。但如果贪心算法挑选出了"**Jane is**"作为前两个词，因为在英语中**going**更加常见，于是对于法语句子来说"**Jane is going**"相比"**Jane is visiting**"会有更高的概率作为法语的翻译，所以很有可能如果你仅仅根据前两个词来估计第三个词的可能性，得到的就是**going**，最终你会得到一个欠佳的句子，在$P(y|x)$模型中这不是一个最好的选择。

## 集束搜索

集束搜索（Beam Search）会考虑每个时间步多个可能的选择。设定一个**集束宽（Beam Width）**$B$，代表了解码器中每个时间步的预选单词数量。

$B=3$，则将第一个时间步最可能的三个预选单词及其概率值 $P(\hat y^{⟨1⟩}|x)$ 保存到内存，以待后续使用。

第二步中，分别将三个预选词作为第二个时间步的输入，得到 $P(\hat y^{⟨2⟩}|x, \hat y^{⟨1⟩})$。

因为我们需要的其实是第一个和第二个单词对（而非只有第二个单词）有着最大概率，因此根据条件概率公式，有：

$$
P(\hat y^{⟨1⟩}, \hat y^{⟨2⟩}|x) = P(\hat y^{⟨1⟩}|x) P(\hat y^{⟨2⟩}|x, \hat y^{⟨1⟩})
$$
设词典中有 $N$ 个词，则当 $B=3$ 时，有 $3N$ 个 $P(\hat y^{⟨1⟩}, \hat y^{⟨2⟩}|x)$。仍然取其中概率值最大的 3 个，作为对应第一个词条件下的第二个词的预选词。以此类推，最后输出一个最优的结果，即结果符合公式：

$$
\arg\max \prod^{T_y}_{t=1} P(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})
$$
可以看到，当 $B=1$ 时，集束搜索就变为贪心搜索。

![Beam-search](img\Beam-search.jpg)

### 改进集束搜索：长度标准化

束搜索就是概率最大化 $\arg\max \prod^{T_y}_{t=1} P(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})$ ，长度标准化（Length Normalization）是对集束搜索算法的优化方式。

当多个小于 1 的概率值相乘后，会造成数值下溢（Numerical Underflow），即得到的结果将会是一个电脑不能精确表示的极小浮点数。因此在实际工作中，我们总是记录概率的对数和，而不是概率的乘积。

对于这样的目标函数，如果有一个很长的句子，那么它的概率会很低，因为乘了很多项小于1的数字来估计概率。缺点是：它倾向于简短的翻译结果，更偏向短的输出，因为短句子的概率是由更少数量的小于1的数字乘积得到的，所以这个乘积不会那么小。于是不再最大化目标函数，而是除以翻译结果的单词数量把它标准化。

在实践中，有个探索性的方法，相比于直接除$T_{y}$，也就是输出句子的单词总数，我们有时会用一个更柔和的方法。在 $T_{y}$ 上加上指数$a$，$a$可以等于0.7。如果$a$等于1，就相当于完全用长度来归一化，如果$a$等于0，$T_{y}$的0次幂就是1，就相当于没有归一化，这就是在完全归一化和没有归一化之间。$a$ 就是算法另一个超参数（**hyper parameter**），需要调整大小来得到最好的结果。不得不承认，这样用 $a$ 实际上是试探性的，它没有理论验证，但大家都发现效果很好。
$$
\arg \max \frac{1}{T_y^{\alpha}} \sum^{T_y}_{t=1} logP(\hat y^{⟨t⟩} | x, \hat y^{⟨1⟩}, ..., \hat y^{⟨t-1⟩})
$$
其中，$T_y$ 是翻译结果的单词数量，$\alpha$ 是一个需要根据实际情况进行调节的超参数。标准化用于减少对输出长的结果的惩罚（因为翻译结果一般没有长度限制）。

关于集束宽 $B$ 的取值，较大的 $B$ 值意味着可能更好的结果和巨大的计算成本；而较小的 $B$ 值代表较小的计算成本和可能表现较差的结果。通常来说，$B$ 可以取一个 10 以下的值。

和 BFS、DFS 等精确的查找算法相比，集束搜索算法运行速度更快，但是不能保证一定找到 $\arg \max$ 准确的最大值。

### 误差分析

集束搜索是一种启发式搜索算法（也就是没道理），其输出结果不总为最优。当结合 Seq2Seq 模型和集束搜索算法所构建的系统出错（没有输出最佳翻译结果）时，我们通过误差分析来分析错误出现在 RNN 模型还是集束搜索算法中。对于下述两个由人工和算法得到的翻译结果：

$$
\begin{aligned}
&\text{Human: Jane visits Africa in September. (y^*)}\\
&\text{Algorithm: Jane visited Africa last September. (y^*)}
\end{aligned}
$$


将翻译中没有太大差别的前三个单词作为解码器前三个时间步的输入，得到第四个时间步的条件概率 $P(y^* | x)$ 和 $P(\hat y | x)$，比较其大小并分析：

* 如果 $P(y^* | x) > P(\hat y | x)$，说明是集束搜索算法出现错误，没有选择到概率最大的词；
* 如果 $P(y^* | x) \le P(\hat y | x)$，说明是 RNN 模型的效果不佳，预测的第四个词为“in”的概率小于“last”。


建立一个如下图所示的表格，记录对每一个错误的分析，有助于判断错误出现在 RNN 模型还是集束搜索算法中。如果错误出现在集束搜索算法中，可以考虑增大集束宽 $B$；否则，需要进一步分析，看是需要正则化、更多数据或是尝试一个不同的网络结构。

![error_analysis_due](img\error_analysis_due.png)

## Bleu 得分

Bleu（Bilingual Evaluation Understudy，双语评估替补）得分用于评估机器翻译的质量，其思想是机器翻译的结果越接近于人工翻译，则评分越高。（参考论文：Papineni, Kishore& Roukos, Salim & Ward, Todd & Zhu, Wei-jing. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation.10.3115/1073083.1073135.）

最原始的 Bleu 是，将机器翻译结果中每个单词在人工翻译中出现的次数作为分子，机器翻译结果总词数作为分母得到。但是容易出现错误：

![Bleu-score-on-unigram](img\Bleu-score-on-unigram.png)

如上，机器翻译结果单纯为某个在人工翻译结果中出现的单词的重复，则按照上述方法得到的 Bleu 为 1，显然有误。

改进的方法是将每个单词在人工翻译结果中出现的次数作为分子，在机器翻译结果中出现的次数作为分母。（每一个单词的记分上限定为它在参考句子中出现的最多次数）

上述方法是以单个词为单位进行统计，以单个词为单位的集合称为**unigram（一元组）**。而以成对的词为单位的集合称为**bigram（二元组）**。对每个二元组，可以统计其在机器翻译结果（$count$）和人工翻译结果（$count_{clip}$）出现的次数，计算 Bleu 得分。

以此类推，以 n 个单词为单位的集合称为**n-gram（多元组）**，对应的 Blue（即翻译精确度）得分计算公式为：

$$
p_n = \frac{\sum_{\text{n-gram} \in \hat y}\mathrm {count_{clip}}(\text{n-gram})}{\sum_{\text{n-gram} \in \hat y}\mathrm {count}(\text{n-gram})}
$$
对 N 个 $p_n$ 进行几何加权平均得到：

$$
p_{ave} = \exp(\frac{1}{N}\sum^N_{i=1}\log^{p_n})
$$
有一个问题是，当机器翻译结果短于人工翻译结果时，比较容易能得到更大的精确度分值，因为输出的大部分词可能都出现在人工翻译结果中。改进的方法是设置一个最佳匹配长度（Best Match Length），如果机器翻译的结果短于该最佳匹配长度，则需要接受简短惩罚（Brevity Penalty，BP）：

$$
BP = 
\begin{cases} 
1, &MT\_length \ge BM\_length \\ 
\exp(1 - \frac{MT\_length}{BM\_length}), &MT\_length \lt BM\_length 
\end{cases}
$$

因此，最后得到的 Bleu 得分为：

$$
Blue = BP \times \exp(\frac{1}{N}\sum^N_{i=1}\log^{p_n})
$$


Bleu 得分的贡献是提出了一个表现不错的**单一实数评估指标**，因此加快了整个机器翻译领域以及其他文本生成领域的进程。

相关论文：[Papineni et. al., 2002. A method for automatic evaluation of machine translation](

### 注意力模型

对于一大段文字，人工翻译一般每次阅读并翻译一小部分。因为难以记忆，很难每次将一大段文字一口气翻译完。同理，用 Seq2Seq 模型建立的翻译系统，对于长句子，Blue 得分会随着输入序列长度的增加而降低。

实际上，我们也并不希望神经网络每次去“记忆”很长一段文字，而是想让它像人工翻译一样工作。因此，注意力模型（Attention Model）被提出。目前，其思想已经成为深度学习领域中最有影响力的思想之一。

对于一大段文字，人工翻译一般每次阅读并翻译一小部分。因为难以记忆，很难每次将一大段文字一口气翻译完。同理，用 Seq2Seq 模型建立的翻译系统，对于长句子，Blue 得分会随着输入序列长度的增加而降低。

实际上，我们也并不希望神经网络每次去“记忆”很长一段文字，而是想让它像人工翻译一样工作。因此，**注意力模型（Attention Model）**被提出。目前，其思想已经成为深度学习领域中最有影响力的思想之一。

![Attention-Model](img\Attention-Model.png)

注意力模型的一个示例网络结构如上图所示。其中，底层是一个双向循环神经网络（BRNN），该网络中每个时间步的激活都包含前向传播和反向传播产生的激活：

$$
a^{\langle t’ \rangle} = ({\overrightarrow a}^{\langle t’ \rangle}, {\overleftarrow a}^{\langle t’ \rangle})
$$
顶层是一个“多对多”结构的循环神经网络，第 $t$ 个时间步的输入包含该网络中前一个时间步的激活 $s^{\langle t-1 \rangle}$、输出 $y^{\langle t-1 \rangle}$ 以及底层的 BRNN 中多个时间步的激活 $c$，其中 $c$ 有（注意分辨 $\alpha$ 和 $a$）：

$$
c^{\langle t \rangle} = \sum_{t’}\alpha^{\langle t,t’ \rangle}a^{\langle t’ \rangle}
$$


其中，参数 $\alpha^{\langle t,t’ \rangle}$ 即代表着 $y^{\langle t \rangle}$ 对 $a^{\langle t' \rangle}$ 的“注意力”，总有：

$$
\sum_{t’}\alpha^{\langle t,t’ \rangle} = 1
$$
我们使用 Softmax 来确保上式成立，因此有：

$$
\alpha^{\langle t,t’ \rangle} = \frac{exp(e^{\langle t,t’ \rangle})}{\sum^{T_x}_{t'=1}exp(e^{\langle t,t’ \rangle})}
$$


而对于 $e^{\langle t,t’ \rangle}$，我们通过神经网络学习得到。输入为 $s^{\langle t-1 \rangle}$ 和 $a^{\langle t’ \rangle}$，如下图所示：

![Computing-attention](img\Computing-attention.png)

注意力模型的一个缺点是时间复杂度为 $O(n^3)$。


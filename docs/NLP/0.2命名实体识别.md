# 命名实体识别 (Name Entity Recognition)



[美团搜索中NER技术的探索与实践 - 美团技术团队](https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html)

[命名实体识别难在哪？_夕小瑶的卖萌屋-CSDN博客](https://blog.csdn.net/xixiaoyaoww/article/details/106846735)

[【NLP-NER】命名实体识别详解之一 - 知乎](https://zhuanlan.zhihu.com/p/88544122)

## 基本概念

实体，可以认为是某一个概念的实例，有点像 OOP 里面对象的概念。例如，“人名”是一种概念，或者说实体类型，那么“蔡英文”就是一种“人名”实体了。“时间”是一种实体类型，那么“中秋节”就是一种“时间”实体了。

所谓实体识别，就是将你想要获取到的实体类型，从一句话里面挑出来的过程。

在一段文本中，将预先定义好的实体类型识别出来。

> 输入：“小丽去深圳参加了腾讯公司的面试”。
> 输出：“小丽[人名] 去 深圳[地名] 参加了 腾讯公司[组织] 的面试”。

识别文本中**具有特定意义的实体**，主要包括人名、地名、机构名、专有名词等

| 小明 | 在   | 北京 | 看了一场 | 中国男篮 | 的比赛 |
| ---- | ---- | ---- | -------- | -------- | ------ |
| PER  |      | LOC  |          | ORG      |        |

NER 是实体关系抽取、信息检索、机器翻译、问答系统等多种自然语言处理技术必不可少的组成部分。

NER是一种序列标注问题，因此他们的数据标注方式也遵照序列标注问题的方式，主要是BIO和BIOES两种。这里直接介绍BIOES，明白了BIOES，BIO也就掌握了。

先列出来BIOES分别代表什么意思：

```python
B，即Begin，表示开始

I，即Intermediate，表示中间

E，即End，表示结尾

S，即Single，表示单个字符

O，即Other，表示其他，用于标记无关字符
```

将“小明在北京大学的燕园看了中国男篮的一场比赛”这句话，进行标注，结果就是：

[B-PER，E-PER，O, B-ORG，I-ORG，I-ORG，E-ORG，O，B-LOC，E-LOC，O，O，B-ORG，I-ORG，I-ORG，E-ORG，O，O，O，O]

那么，换句话说，**NER的过程，就是根据输入的句子，预测出其标注序列的过程。**

还有，它的训练数据集是这样的：

```json
{"text": "浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，", "label": {"name": {"叶老桂": [[9, 11]]}, "company": {"浙商银行": [[0, 3]]}}}
{"text": "生生不息CSOL生化狂潮让你填弹狂扫", "label": {"game": {"CSOL": [[4, 7]]}}}
{"text": "那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？", "label": {"organization": {"那不勒斯": [[0, 3]], "锡耶纳": [[6, 8]], "桑普": [[11, 12]], "热那亚": [[15, 17]]}}}
{"text": "加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》，", "label": {"movie": {"加勒比海盗3：世界尽头》": [[0, 11]], "《变形金刚》": [[33, 38]]}}}
{"text": "布鲁京斯研究所桑顿中国中心研究部主任李成说，东亚的和平与安全，是美国的“核心利益”之一。", "label": {"address": {"美国": [[32, 33]]}, "organization": {"布鲁京斯研究所桑顿中国中心": [[0, 12]]}, "name": {"李成": [[18, 19]]}, "position": {"研究部主任": [[13, 17]]}}}
```

BIO 序列标注方法是这样的：

`阿 巴 查 ８ 日 晨 因 心 脏 病 突 发 在 首 都 阿 布 贾 去 世 。`

`B-PER I-PER I-PER O O O O O O O O O O O O B-LOC I-LOC I-LOC O O O`

### 过程

（1）实体边界识别 —— 判断什么才是实体。

（2）确定实体类别 —— 判断实体属于什么类别。比如在饮品行业中品牌、产品、品牌信息、口味、味道、气味、质感、产地、规格等就是实体。

**命名实体的边界是什么？**

>[命名实体识别难在哪？_夕小瑶的卖萌屋](https://blog.csdn.net/xixiaoyaoww/article/details/106846735)
>
>中文分词任务关注句子中的词汇之间的边界，词性标注关注这些被分出边界的词在词法上的类型。而命名实体识别关注的是命名实体的边界。它的粒度通常比中文分词要粗——是多个单词构成的复合词或短语，比如《那些年，我们一起追过的女孩》，《我们仍未知道那天所看见的花的名字》。它的类别通常比词性标注更具混淆性——是基于自然语言体系构建的抽象世界中，某个领域下的概念归属，比如人名，地名，组织机构名、股票、影视，书籍，游戏，艺术、医学术语等等。这些依托人类想象力构筑的事物，会随着时间的向前而不断变迁。它是信息抽取任务的焦点，在实际生产中需求很迫切，但做起来又很难。

### 问题

（1）命名实体类型多样，数量众多，不断有新的命名实体涌现，难以建立大而全的数据库。

（2）命名实体构成结构比较复杂，存在大量的嵌套、别名、缩略词等问题，没有严格的规律可以遵循;人名中也存在比较长的少数民族人名或翻译过来的外国人名。

（3）不同命名实体之间界限不清晰，人名也经常出现在地名和组织名称中，存在大量的交叉和互相包含现象。常常要涉及上下文语义层面的分析，这些都给命名实体的识别带来困难。

（4）在不同的文化、领域、背景下，命名实体的外延有差异。对命名实体的定界和类型确定，目前还没有形成共同遵循的严格的命名规范。

（5）命名实体识别过程常常要与中文分词、浅层语法分析等过程相结合，分词、语法分析系统的可靠性也直接决定命名实体识别的有效性，使得中文命名实体识别更加困难。

标注资源：

[文本标注工具Brat的安装及使用 - 知乎](https://zhuanlan.zhihu.com/p/129302829)

[文本情感分析有什么好资料、网站、工具推荐呢？ - 知乎](https://www.zhihu.com/question/20631050)

[CLUEbenchmark/CLUENER2020: CLUENER2020 中文细粒度命名实体识别 Fine Grained Named Entity Recognition](https://github.com/CLUEbenchmark/CLUENER2020)

## 基于词典

人工构建有限的规则，再从文本中寻找匹配这些规则的字符串。

1. 虽然能够在特定的语料上获得较高的识别效果。但是识别效果越好，越需要大量规则的制定，而人工制定这些规则可行性太低。
2. 几乎不可能通过制定有限的规则来识别出变化无穷的命名实体。
3. 规则对领域知识极度依赖，当领域差别很大时，制定的规则往往无法移植，不得不重新制定规则。

这些固有的缺点使得研究者们转而采取新的研究思路，而此时正值机器学习在NLP领域兴起，NER也自然地转向了机器学习的阵营。

## 传统方法：基于机器学习

基于机器学习的NER的方法归根结底是分类的方法。给定命名实体的多个类别，再使用模型对文本中的实体进行分类。分为两种思路：

1. 先识别出文本中所有命名实体的边界，再对这些命名实体进行分类。
2. 序列化标注方法。利用大规模语料学习出标注模型，再对句子的各个位置进行标注。常用的模型有隐马尔可夫模型(Hidden Markov Model,   HMM)和条件随机场(Conditional Random Field，CRF)等。

### HMM

(见 第三章)

隐马尔可夫模型（Hidden Markov Model，HMM）创建于上世纪70年代，是一个统计模型。HMM的系统中存在两条序列：

- 一个是可以直接通过观测得到的观察序列，在NER中指每一个词语本身；
- 另一个是隐含的状态转移序列，指每个词语背后的标注。我们要做的就是求观察序列的背后最可能的标注序列。即根据输入的一系列单词，去生成其背后的标注，从而得到实体

### CRF

条件随机场（Conditional Random Field，CRF）是NER目前的主流模型。假设 𝑋 表示待标记的观测序列， 𝑌 表示隐状态序列，𝑃(𝑌|𝑋)表示给定 𝑋 的条件下 𝑌 的条件概率，随机变量 𝑌 满足
$$
P\left(Y_{v} \mid X, Y_{w}, w \neq v\right)=P\left(Y_{v} \mid X, Y_{w}, w \sim v\right)
$$

## 最近的方法：基于深度学习

近年来  ，随着硬件计算能力的发展以及 word-embedding 的提出，神经网络已经成为一个可以有效处理许多NLP任务的模型。在NER任务中，传统的神经网络的处理方式：

- 先将句子中的所有单词表示为 word-embedding；
- 随后将句子的 embedding 序列输入到神经网络中，用神经网络自动提取特征；
- 最后通过一层 Softmax 来预测每个token的标签。其中，神经网络通常采用RNN，LSTM，BiLSTM等

## 常用方法总结

与关系提取类似，NER 也有：

- 基于规则与词典的模式匹配方法：类似于词表匹配，这种方法准确率高，召回率低，对于新词缺乏发现能力，并且往往需要领域专家帮忙维护知识库。
- 无监督学习方法：比较典型的是基于聚类的方法。 *D. Nadeau and S. Sekine, “A survey of named entity recognition and classification,” Lingvisticae Investigationes, vol. 30, no. 1, pp 3–26, 2007.）*
- 监督学习方法：分类模型，如SVM, 决策树, Adaboost 等，通常将每个字符的标签当成一个类别进行文本分类；而序列标注模型如CRF等，通常将NER问题理解为一个最大概率序列的问题，根据观测序列（通常指字符）预测隐藏序列（字符的标签）。常用的特征包括但不限于词是否再句子第一个位置出现；词缀，前缀和后缀等；目标词前后n个字符划定窗口，窗口内词的词性，orthographic等等。


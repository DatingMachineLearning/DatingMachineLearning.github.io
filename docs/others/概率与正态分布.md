## 概率分支

对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派。后面我们对观测集采用下面记号：
$$
X_{N\times p}=(x_{1},x_{2},\cdots,x_{N})^{T},x_{i}=(x_{i1},x_{i2},\cdots,x_{ip})^{T}
$$
 这个记号表示有 $N$ 个样本，每个样本都是 $p$ 维向量。其中每个观测都是由 $p(x|\theta)$ 生成的。

https://yangfangs.github.io/2018/04/06/the-different-of-likelihood-and-probability/

https://www.zhihu.com/question/24261751

在[数理统计学](https://zh.wikipedia.org/wiki/数理统计学)中，**似然函数（**英语：likelihood function）是一种关于[统计模型](https://zh.wikipedia.org/wiki/统计模型)中的[参数](https://zh.wikipedia.org/wiki/母數)的[函数](https://zh.wikipedia.org/wiki/函数)，表示模型参数中的**似然性**（英语：likelihood）。文字意义上，“似然性”与“或然性”或“[概率](https://zh.wikipedia.org/wiki/概率)”意思相近，都是指某种事件发生的可能性，但是在[统计学](https://zh.wikipedia.org/wiki/统计学)中，“似然性”和“概率”（或然性）有明确的区分：概率，用于在已知一些参数的情况下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值，也就是说已观察到某事件后，对相关参数进行猜测。

在已知某个参数 $\alpha$ 时，事件 $A$ 会发生的条件概率可以写作 $P(A;\alpha)$，也就是 $P(A|\alpha)$。我们也可以构造似然性的方法来表示事件 $A$ 发生后估计参数 $\alpha$ 的可能性，也就表示为 $L(\alpha |A)$，其中 $L(\alpha |A) = P(A|\alpha)$。

### 频率派

$p(x|\theta)$中的 $\theta$ 是一个常量。对于 $N$ 个观测来说观测集的概率为 $p(X|\theta)\mathop{=}\limits _{iid}\prod\limits _{i=1}^{N}p(x_{i}|\theta))$ 。为了求 $\theta$ 的大小，我们采用最大对数似然MLE的方法：

$$
\theta_{MLE}=\mathop{\arg\max}\limits _{\theta}\log p(X|\theta)\mathop{=}\limits _{iid}\mathop{\arg\max}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)
$$

### 贝叶斯派

贝叶斯派认为 $p(x|\theta)$ 中的 $\theta$ 不是一个常量。这个 $\theta$ 满足一个预设的先验的分布 $\theta\sim p(\theta)$ 。于是根据贝叶斯定理依赖观测集参数的后验可以写成：

$$
p(\theta|X)=\frac{p(X|\theta)\cdot p(\theta)}{p(X)}=\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}
$$
为了求 $\theta$ 的值，我们要最大化这个参数后验MAP：


$$
\theta_{MAP}=\mathop{\arg\max}\limits _{\theta}p(\theta|X)=\mathop{\arg\max}\limits _{\theta}p(X|\theta)\cdot p(\theta)
$$
其中第二个等号是由于分母和 $\theta$ 没有关系。求解这个 $\theta$ 值后计算$\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}$ ，就得到了参数的后验概率。其中 $p(X|\theta)$ 叫似然，是我们的模型分布。得到了参数的后验分布后，我们可以将这个分布用于预测贝叶斯预测：
$$
p(x_{new}|X)=\int\limits _{\theta}p(x_{new}|\theta)\cdot p(\theta|X)d\theta
$$
其中积分中的被乘数是模型，乘数是后验分布。

频率派和贝叶斯派分别给出了一系列的机器学习算法。频率派的观点导出了一系列的统计机器学习算法而贝叶斯派导出了概率图理论。在应用频率派的 MLE 方法时最优化理论占有重要地位。而贝叶斯派的算法无论是后验概率的建模还是应用这个后验进行推断时积分占有重要地位。因此采样积分方法如 MCMC 有很多应用。

## 正态分布

### MLE

高斯分布在机器学习中占有举足轻重的作用。在 MLE 方法中，参数有均值 $\mu$ 和方差 $\Sigma$ （高维情况的正定矩阵）。

$$
\begin{aligned}
&\theta=(\mu,\Sigma)=(\mu,\sigma^{2}) \\

\\
&
\begin{aligned}
\theta_{MLE} &=\mathop{\arg\max}\limits _{\theta}\log p(X|\theta)
\\
& \mathop{=}\limits _{iid}\mathop{\arg\max}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)
\end{aligned}

\end{aligned}
$$
一般地，对于样本 $x_{i}=(x_{i1},x_{i2},\cdots,x_{ip})^{T}$，高斯分布的概率密度函数写为：

$$
p(x|\mu,\Sigma)=\frac{1}{\sqrt{(2\pi)^{p }|\Sigma|}}\exp[{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)}]
$$
若考虑一维的情况：
$$
\log p(X|\theta)=\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)=\sum\limits _{i=1}^{N}\log\frac{1}{\sqrt{2\pi}\sigma}\exp(-(x_{i}-\mu)^{2}/2\sigma^{2})
$$
利用 MLE算出参数 $\mu$：
$$
\begin{aligned} &
\begin{aligned}
\mu_{\rm MLE}
&=\mathop{\arg\max}\limits _{\mu}\log p(X|\theta)
\\ &=\mathop{\arg\max}\limits _{\mu}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}
\end{aligned}
\\&
\begin{aligned}
\frac{\partial}{\partial\mu}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}=0 

\Rightarrow \mu_{MLE}=\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}
\end{aligned}

\end{aligned}
$$
同样算出 $\sigma$
$$
\begin{aligned}
\sigma_{\rm MLE} 
&=\mathop{argmax}\limits _{\sigma}\log p(X|\theta) \\
&=\mathop{argmax}\limits _{\sigma}\sum\limits _{i=1}^{N}[-\log\sigma-\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}] \\
&=\mathop{argmin}\limits _{\sigma}\sum\limits _{i=1}^{N}[\log\sigma+\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}]
\end{aligned}

\\
\frac{\partial}{\partial\sigma}\sum\limits _{i=1}^{N}[\log\sigma+\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}]=0\Rightarrow\sigma_{MLE}^{2}=\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}
$$
值得注意的是，上面的推导中，首先对 $\mu$ 求 MLE， 然后利用这个结果求 $\sigma_{MLE}$ ，因此可以预期的是对数据集求期望时 $\mathbb{E}_{\mathcal{D}}[\mu_{\rm MLE}]$ 是无偏差的：
$$
\mathbb{E}_{\mathcal{D}}[\mu_{\rm MLE}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}]=\frac{1}{N}\sum\limits _{i=1}^{N}\mathbb{E}_{\mathcal{D}}[x_{i}]=\mu
$$
但是当对 $\sigma_{\rm MLE}$ 求 期望的时候由于使用了单个数据集的 $\mu_{MLE}$，因此对所有数据集求期望的时候我们会发现 $\sigma_{\rm MLE}$ 是 有偏的：

$$
\begin{align}
\mathbb{E}_{\mathcal{D}}[\sigma_{{\rm MLE}}^{2}]&=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}-\mu_{{\rm MLE}})^{2}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}^{2}-2x_{i}\mu_{{\rm MLE}}+\mu_{{\rm MLE}}^{2})\nonumber
\\&=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu_{{\rm MLE}}^{2}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu^{2}+\mu^{2}-\mu_{{\rm MLE}}^{2}]\nonumber\\
&= \mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu^{2}]-\mathbb{E}_{\mathcal{D}}[\mu_{{\rm MLE}}^{2}-\mu^{2}]=\sigma^{2}-(\mathbb{E}_{\mathcal{D}}[\mu_{{\rm MLE}}^{2}]-\mu^{2})\nonumber\\&=\sigma^{2}-(\mathbb{E}_{\mathcal{D}}[\mu_{{\rm MLE}}^{2}]-\mathbb{E}_{\mathcal{D}}^{2}[\mu_{{\rm MLE}}])=\sigma^{2}-Var[\mu_{{\rm MLE}}]\nonumber\\&=\sigma^{2}-Var[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}]

\\ &=\sigma^{2}-\frac{1}{N^{2}}\sum\limits _{i=1}^{N}Var[x_{i}]
\\ &=\frac{N-1}{N}\sigma^{2}
\end{align}
$$
所以：
$$
\hat{\sigma}^{2}=\frac{1}{N-1}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}
$$


### 

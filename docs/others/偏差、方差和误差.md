偏差和方差是训练机器学习模型时需要调整的核心参数。

## TL:DR

简单来说是：

`误差 error = 方差 variance + 偏差 bias`

偏差是通过学习拟合出来模型的期望，与**真实规律**之间的差距。

方差是模型每一次输出结果与**模型输出期望**之间的误差，即模型的稳定性。

## 详解

### 偏差

比如现在有一些学生的二维数据，身高和体重。这些数据满足 f 分布。f 是一个多项式的函数。

我们用一根**直线**去拟合数据（最小二乘法），偏差会很大，因为真实的是多项式的，我们的直线预测出的结果可能跟真实情况有出入。

如果我们用**多项式**函数去拟合数据，偏差就会很小，因为模型变得更加复杂了。

偏差是通过学习拟合出来的结果的期望，与真实规律之间的差距。即：
$$
\mathrm {Bias}(X) = E(\hat{f}(x)) - f(x)
$$


![img](https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210624114952.jpeg)

### 方差

若我们用多项式拟合，就会有一个问题：数据是存在噪音的，而噪音更容易影响复杂模型。带噪数据训练的直线模型，和无噪音的数据训练的直线模型是差不多的，很稳定，而在同样的情况下，多项式模型就容易受影响。

![img](https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210624114911.jpeg)



方差是模型每一次输出结果与**模型输出期望**之间的误差，即模型的稳定性：
$$
\mathrm {Variance}(X) = E[(\hat f(X) - E[\hat f(X)])^2]
$$


> If Bias vs Variance was the act of reading, it could be like Skimming a Text vs Memorizing a Text
>
> 如果偏差 vs 方差是阅读的行为，它可能就像略读文本 vs 记忆文本

### 欠拟合与过拟合

简单的模型一般偏差很高，是欠拟合 (unfitting) 的，为了减少偏差，就要增加模型复杂度，增加参数或减少减少正则化。

复杂的模型一般方差较高，是过拟合的 (overfitting) ，为了降低方差，就要减少复杂度，一般用正则化方法或者换简单模型。

在机器学习中我们要选择恰当的模型复杂度。



参考：

> https://www.zhihu.com/question/27068705/answer/1689740820
>
> https://liam.page/2017/03/25/bias-variance-tradeoff/
>
> http://scott.fortmann-roe.com/docs/BiasVariance.html


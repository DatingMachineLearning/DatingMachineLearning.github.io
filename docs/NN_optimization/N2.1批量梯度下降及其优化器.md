# 机器学习优化算法

深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。

## 批量梯度下降法 Batch Gradient Descent 

**batch 梯度下降法**（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新。

对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。

但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 **mini-batch**。

## 小批量梯度下降法 Mini-Batch Gradient Descent 

小批量梯度下降法每次同时处理**单个**的 mini-batch，其他与 batch 梯度下降法一致。

使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 的个数的梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。

batch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下：

![training-with-mini-batch-gradient-descent](https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210627153553.png)

### batch 的不同大小带来的影响

* mini-batch 的大小为 1，即是**随机梯度下降法（stochastic gradient descent）**，每个样本都是独立的 mini-batch。看到多了随机两个字，随机也就是说我们用样本中的一个例子来近似所有的样本；
* mini-batch 的大小为 m，即是 batch 梯度下降法；

![choosing-mini-batch-size](https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210627153619.png)

* batch 梯度下降法：
  * 对所有 m 个训练样本执行一次梯度下降，**每一次迭代时间较长，训练过程慢**； 
  * 相对噪声低一些，幅度也大一些；
  * 成本函数总是向减小的方向下降。

* 随机梯度下降法：
  * 对每一个训练样本执行一次梯度下降，训练速度快，但**丢失了向量化带来的计算加速**；
  * 有很多噪声，减小学习率可以适当；
  * 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。

因此，选择一个`1 < size < m`的合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。

### mini-batch 大小的选择

* 如果训练样本的大小比较小，如 $m ⩽ 2000$ 时，选择 batch 梯度下降法；
* 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 $2^6$、$2^7$、...、$2^9$；
* mini-batch 的大小要符合 CPU/GPU 内存。

mini-batch 的大小也是一个重要的超参数，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。

### 问题

1. 随机梯度下降的 batch-size设置成多少合适？过小有什么问题？过大有什么问题？提示：过大以整个样本集合为例，过小以单个样本为例来思考。

2. 一次训练使用的配置：5个epoch，1000个样本，batch-size = 20，最内层循环执行多少轮？

### 答案

> 1. 128（batch size 需要调参）
>
>    过大：
>
>    - batch size太大，memory容易不够用。这个很显然，就不多说了。
>
>    - batch size太大，深度学习的优化（training loss降不下去）和泛化（generalization gap很大）都会出问题。
>
>    过小：
>
>    - 当你的 batch size太小的时候，在一定的epoch数里，训练出来的参数 posterior 是根本来不及接近 long-time limit 的定态分布。来不及收敛。
>
>    合适的batch size范围主要和收敛速度、随机梯度噪音有关。[怎么选取训练神经网络时的Batch size? - 知乎 (zhihu.com)](https://www.zhihu.com/question/61607442)
>
>    [训练神经网络时如何确定batch的大小？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484570&idx=1&sn=4c0b6b76a7f2518d77818535b677e087&chksm=970c2c4ca07ba55ad5cfe6b46f72dbef85a159574fb60b9932404e45747c95eed8c6c0f66d62#rd)
>
> 2. 最外层 5 次，最内层 50 次。

## 指数平均加权

**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，计算公式为：
$$
v_t = 
\begin{cases} 
\theta_1, &t = 1 \\\\ 
\beta v_{t-1} + (1-\beta)\theta_t, &t > 1 
\end{cases}
$$

其中 $\theta_t$ 为 t 下的实际值，$v_t$ 为 t 下加权平均后的值，β 为权重值。

指数加权平均数在统计学中被称为“指数加权移动平均值”。

给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。

当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线。**β 越大相当于求取平均利用的天数越多**，曲线自然就会越平滑而且越滞后。

<img src="https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210628174818.png" alt="{699793C6-5747-44D7-B9C8-EE188E9134F4}" style="zoom:67%;" />

当 β 为 0.9 时，

$$
v_{100} = 0.9v_{99} + 0.1 \theta_{100} \\
v_{99} = 0.9v_{98} + 0.1 \theta_{99} \\
v_{98} = 0.9v_{97} + 0.1 \theta_{98} \\
\dots
$$
展开：
$$
v_{100} = 0.1 \theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^2 \theta_{98} + ...
$$
其中 $θ_i$ 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作**偏差修正（Bias Correction）**。

$$
{\lim_{\beta\to 0}}(1 - \beta)^{\frac{1}{\beta}} = \frac{1}{e} \approx 0.368
$$
本质就是以指数式递减加权的移动平均。各数值的加权而随时间而指数式递减，越近期的数据加权越重，但较旧的数据也给予一定的加权。

而在我们上面提到的普通平均数求法，它的每一项的权值都是一样的，如果有n项，权值都为1/n。

**指数加权平均的结果是由当天温度值乘以指数衰减函数值，再求和**

我们可以看到指数加权平均的求解过程实际上是一个递推的过程，那么这样就会有一个非常大的好处，每当我要求从0到某一时刻（n）的平均值的时候，我并不需要像普通求解平均值的作为，保留所有的时刻值，类和然后除以n。

而是只需要保留 0 到 (n-1)时刻的平均值和 n 时刻的温度值即可。也就是每次只需要保留常数值，然后进行运算即可，这对于深度学习中的海量数据来说，是一个很好的减少内存和空间的做法。

```python
for i in range(t_num):
    V[t] = beta * V[t - 1] + (1 - beta) * Theta[t]
```

## 指数平均加权的偏差修正

我们通常有

$$
v_0 = 0\\
v_1 = 0.98v_0 + 0.02\theta_1
$$
因此，$v_1$ 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。

因此，我们修改公式为

$$
v_t = \frac{\beta v_{t-1} + (1 - \beta)\theta_t}{{1-\beta^t}}
$$
随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。

## 动量梯度下降法

动量梯度下降（Gradient Descent with Momentum）是计算梯度的指数加权平均数，并利用该值来更新参数值。具体过程为：

$$
\begin{aligned}
\text{for } &l = 1, \cdots, L: \\

&v_{\mathrm d W^{[l]}} = \beta v_{\mathrm d W^{[l]}} + (1 - \beta) \mathrm d W^{[l]} \\
&v_{\mathrm d b^{[l]}} = \beta v_{\mathrm d b^{[l]}} + (1 - \beta) \mathrm d b^{[l]} \\
&W^{[l]} := W^{[l]} - \alpha v_{\mathrm d W^{[l]}} \\
&b^{[l]} := b^{[l]} - \alpha v_{\mathrm d b^{[l]}}
\end {aligned}
$$
其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。

![img](https://gitee.com/xrandx/blog-figurebed/raw/master/img/20210709152317.png)

进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。

而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。

另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。

### 动量梯度下降法的形象解释

将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 $v_{dw}$、$v_{db}$ 相当于速度。

小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。

## RMSProp 算法

RMSProp（Root Mean Square Propagation，均方根传播）算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。具体过程为：
$$
\begin{aligned}
s_{\mathrm dW} &= \beta s_{\mathrm dW} + (1 - \beta)(\mathrm d W)^2 \\
s_{\mathrm db} &= \beta s_{\mathrm db} + (1 - \beta)(\mathrm d b)^2 \\ 
W &:= W - \alpha \frac{\mathrm dW}{\sqrt{s_{\mathrm dW} + \epsilon}} \\
b &:= b - \alpha \frac{\mathrm db}{\sqrt{s_{\mathrm db} + \epsilon}} \\
\end{aligned}
$$


其中，ϵ 是一个实际操作时加上的较小数（例如$10^{-8}$），为了防止分母太小而导致的数值不稳定。

当 dW 或 db 较大时，$(\mathrm dW)^2$、$(\mathrm db)^2$会较大，进而 $s_{\mathrm d w}$、$s_{\mathrm d b}$也会较大，最终使得 $\frac{\mathrm d w}{\sqrt{s_{\mathrm d w} + \epsilon}}$ 和 $\frac{\mathrm db}{\sqrt{s_{\mathrm d b} + \epsilon}}$ 较小，从而减小某些维度梯度更新波动较大的情况，使下降速度变得更快。

![RMSProp](https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Improving_Deep_Neural_Networks/RMSProp.png)

RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。并且，它和 Adam 优化算法已被证明适用于不同的深度学习网络结构。

注意，β 也是一个超参数。

## Adam 优化算法

Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）基本上就是将 Momentum 和 RMSProp 算法结合在一起，结合了 AdaGrad 和 RMSProp 的优点。Adam 对每个参数使用相同的学习率，并随着学习的进行而独立地适应。此外，Adam 是基于动量的算法，利用了梯度的历史信息。基于这些特征，在选择优化算法时，Adam 往往是「当仁不让」。具体过程如下：

首先进行初始化，

$$
v_{\mathrm dW} = 0, s_{\mathrm dW} = 0, v_{\mathrm d b} = 0, s_{\mathrm d b} = 0
$$
用每一个 mini-batch 计算 $\mathrm dW$、$\mathrm d b$，第 t 次迭代时：
$$
\begin{aligned}
v_{\mathrm dW} &= \beta_1 v_{\mathrm dW} + (1 - \beta_1) \mathrm dW \\ 
v_{\mathrm d b} &= \beta_1 v_{\mathrm d b} + (1 - \beta_1) \mathrm d b \\ 
s_{\mathrm dW} &= \beta_2 s_{\mathrm dW} + (1 - \beta_2) {(\mathrm dW)}^2 \\ 
s_{\mathrm d b} &= \beta_2 s_{\mathrm d b} + (1 - \beta_2) {(\mathrm d b)}^2 \\
\end{aligned}
$$
一般使用 Adam 算法时需要计算偏差修正：
$$
\begin{aligned}
v^{\text{corrected}}_{\mathrm dW} &= \frac{v_{\mathrm dW}}{1-{\beta_1}^t} \\
v^{\text{corrected}}_{\mathrm d b} &= \frac{v_{\mathrm d b}}{1-{\beta_1}^t} \\
s^{\text{corrected}}_{\mathrm dW} &= \frac{s_{\mathrm dW}}{1-{\beta_2}^t} \\
s^{\text{corrected}}_{\mathrm d b} &= \frac{s_{\mathrm d b}}{1-{\beta_2}^t} \\
\end{aligned}
$$
所以，更新 W、b 时有：

$$
W := W - \alpha \frac{v^{\text{corrected}}_{\mathrm dW}}{{\sqrt{s^{\text{corrected}}_{\mathrm dW}} + \epsilon}}
\\
b := b - \alpha \frac{v^{\text{corrected}}_{\mathrm d b}}{{\sqrt{s^{\text{corrected}}_{\mathrm d b}} + \epsilon}}
$$
（可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大）

### 超参数的选择

Adam 优化算法有很多的超参数，其中

* 学习率 α：需要尝试一系列的值，来寻找比较合适的；
* β1：常用的缺省值为 0.9；
* β2：Adam 算法的作者建议为 0.999；
* ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 $10^{-8}$；

β1、β2、ϵ 通常不需要调试。



## 参考

吴恩达，深度学习课程
